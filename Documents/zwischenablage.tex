\begin{document}

\begin{comment}
%%%%%%%%%%%%%%%%% THE COMMENT

\def\partname{Phase}
\part[Projektplanung Phase I]{Projektplanung}
\def\partname{Teil}

\chapter{Teamorganisation}

\section{Themengebiete}
Da die Problematik einen hohen Grad an visuellen Erkennungsproblemen mit hoher Komplexität enthält und dieses Softwareprojekt vom Fachgebiet für Neuroinformatik und Kognitive Robotik gestellt wird, liegt es nahe und ist ebenso im Lastenheft gefordert, \glslink{Neuronales Netzwerk}{Neuronale Netzwerke} zu deren Bewältigung einzusetzen. Aus diesem Grunde werden zwei Themengruppen jeweils für die Entwicklung von einem oder mehreren \glslink{Neuronales Netzwerk}{Detektionsnetzwerken} und einem oder mehreren \glslink{Neuronales Netzwerk}{Klassifikatornetzwerken} abgestellt. Ein weiteres Team entwickelt die gewünschte  \gls{Filterverwaltungs-Bibliothek}  und die darauf aufsetzende \gls{Verkehrszeichen-API}. Das letzte Team erstellt die \gls{App} als Frontend und Benutzerschnittstelle für das Projekt.\\

\section{Rollenverteilung}

\begin{longtabu}{l l X[j]}
\hline
\bf Themengebiet & \bf Mitglieder & \bf Aufgaben\\
\hline
Bibliothek & Patrick Langer & \gls{Filterverwaltungs-Bibliothek}, \\ 
&& \gls{Verkehrszeichen-API},\\
&& \gls{TensorFlow Lite}-Anbindung \\
\hline
\gls{Detektion} & Robert Niklas Bock, & Netzwerkarchitektur, \\
& Söhnke Benedikt Fischedick, & Erkennungsstrategien, \\
& Florian Köhler & \gls{Tracking} \\
\hline
\gls{Klassifikation} & Tim Treichel, & Klassifikationsnetzwerke \\
& Mohammad Dirbas & \\
\hline
\gls{App} & Jakob Frank Hampel, & Benutzeroberfläche,\\
& Yusuf Nowati, & Kameraanbindung,\\
& Florian Köhler & Sonstiges\\
\hline
\end{longtabu}

\section{Kommunikationswege}
Zur Fernkommunikation sind alle Mitglieder unseres Projektes in eine dedizierte WhatsApp-Gruppe eingeschrieben. Zudem werden wichtige virtuelle Gespräche über die Kommunikationsplattform Skype abgehalten. Die interne Absprache in den Themengruppen ist jedem selbst überlassen.
Zur Kommunikation zwischen Gruppe und Betreuer wird der klassische Weg über E-Mails verwendet.
\\
\section{Gruppentreffen}
Regelmäßige Gruppentreffen mit den Betreuern sind aller zwei Wochen am Donnerstag um 9:00 Uhr angesetzt. Diese dienen zum Abgleich des Fortschritts und zur Klärung von Problemen und Fragen.
Treffen ohne Betreuer werden nach Bedarf festgelegt um themengebietsübergreifende Absprachen und Abgleiche durchzuführen. Interne Treffen in den Themengruppen sind wieder jedem selbst zur Planung überlassen. Für jedes Treffen der gesamten Gruppe wird ein Protokoll angefertigt.


\chapter{Vorgehen}

\section{Wahl des Vorgehensmodells}

Die Wahl des Vorgehensmodells für das Softwareprojekt wurde durch die Auftraggeber nicht festgelegt.
Die Wahl fiel auf das agile Vorgehensmodell, da dieses aufgrund der Flexbilität am ehesten den Anforderungen des Projektes gerecht wird: Aufgrund der Unvorhersehbarkeit des Erfolges gewählter Strategien und Lösungsansätze muss dynamisch auf neue Erkenntnisse und ggf. Fehlschläge reagiert werden und das Vorgehen dementsprechend angepasst werden.
In einem so stark umforschten Themengebiet wie dem  \gls{Deep Learning}, welches viel Austesten benötigt, ist es vorteilhaft nicht an ein zu Beginn festgelegtes Schema gebunden zu sein und stets notwendige Änderungen vornehmen zu können.
Diese Vorteile sind auch teils bei Unified Process gegeben, allerdings ist die noch freiere Handhabung im agilen Vorgehen adäquater für die Projekt-Gruppe.
\\
\subsection{Anpassungen}
Als Grundkonzept des agilen Vorgehensmodells gelten die Bestimmungen, welche auf der Website des Fachgebiets System- und Software-Engineering\footlink{https://www.tu-ilmenau.de/sse/lehre/softwareprojekt/projektablauf/}{29.04.2018} vorgeschrieben sind. Davon abweichend wird die Gruppe in Teams unterteilt, um verschiedene Designs für \glslink{Neuronales Netzwerk}{Neuronale Netzwerke} zu bearbeiten, da eine gemeinschaftliche Arbeit daran, mit mehr als drei Personen nicht sinnvoll ist. Aufgrund des Umfangs und Einarbeitungsaufwands für die einzelnen Themen ist es im Rahmen des Softwareprojektes schlichtweg nicht möglich, dass jedes Gruppenmitglied alle Teilgebiete des Projekts vollständig beherrscht.
\\

\section{Richtlinien, Werte und Prinzipien}

\subsection{Inkrementelles, iteratives und evolutionäres Vorgehen}
Die Entwicklung beinhaltet Teile aus allen drei Vorgehenssystemen. Durch die allgemeinen Anforderungen an das Softwareprojekt stellt die inkrementelle Entwicklung eine wichtige Basis dar: Ein entwickeltes Grobkonzept dient als Grundlage für die Software, welche die wichtigsten Anforderungen umfasst. Abhängig vom Projektverlauf könnte sich eine evolutionäre Erweiterung der Anforderungen als sinnvoll erweisen. Zudem wird durch die Vorgabe der drei Phasen eine dreifache Iteration mit stets funktionsfähigen und zu erweiternden Prototypen vorgegeben. 
\\

\subsection{Kommunikation statt Dokumentation}
In der Projektplanung und Durchführung wird das persönliche Gespräch in der Gruppe und den Teilgruppen gegenüber einer detaillierteren Dokumentation vorgezogen. Wichtige Punkte müssen zwar schriftlich festgehalten werden, allerdings ist es zu priorisieren, dass alle Betroffenen diese einheitlich verstanden und diskutiert haben.
\\

\subsection{Selbstorganisation des Teams}
Das Team teilt sich selbstständig auf die wichtigsten Themengebiete auf. Damit wird es möglich, die verschiedenen Stärken einzelner Mitglieder gezielter einzusetzen und den Lernaufwand neuer Inhalte für den Rest zu minimalisieren. Je nach Entwicklung des Projektes ist vorbehalten, die Struktur den Gegebenheiten anzupassen.
\\

\subsection{Gemeinsamer Codebesitz}
Trotz der Aufteilung des Teams in Themengruppen soll der Code dennoch in gemeinsamen Besitz bleiben. Somit ist es Personen bei Bedarf möglich, bei anderen Themen Aufgaben zu übernehmen.
Der Code wird durch den vom Fachgebiet Neuroinformatik und Kognitive Robotik der TU Ilmenau bereitgestellten GitLab-Zugang verwaltet.
\\

\subsection{Coding Rules}
\label{subsec:code_rules}
Um das bei Bedarf eingeplante dynamische Verteilen von Aufgaben zu vereinfachen, sind vorher definierte Regeln über den Style des zu schreibenden Codes notwendig. Die Vereinheitlichung ermöglicht ein schnelles Einarbeiten in fremden Code.\\

\subsubsection{Python}
Für Python gelten als Standard der PEP 8 Style-Guide\footlink{https://www.python.org/dev/peps/pep-0008/}{27.04.2018} für Code sowie der NumPyDoc DocString Guide\footlink{http://numpydoc.readthedocs.io/en/latest/format.html}{27.04.2018} für Dokumentations-Kommentare.\\

\subsubsection{C++}
Für C++ gelten als Standard die GeoSoft C++ Programming Style Guidelines\footlink{http://geosoft.no/development/cppstyle.html\#General}{29.04.18} für Code sowie der Apache Mesos Doxygen Style Guide\footlinklabel{http://mesos.apache.org/documentation/latest/doxygen-style-guide/}{29.04.18}{foot:guideline} für Dokumentations-Kommentare.\\

\subsubsection{Java \& Android Studio Projekt}
Für Android Studio Projekte auch im Bezug auf Java, gelten als Standard die Android Project And Code Guidelines der Ribot Ltd.\footlink{https://github.com/ribot/android-guidelines/blob/master/project\_and\_code\_guidelines.md}{29.04.18}, mit Außnahme von Punkt 2.2.5: Geschweifte Klammern stehen stets einzeln in einer eigenen Zeile. Als Dokumentationsstandard gilt der Apache Mesos Doxygen Style Guide\footref{foot:guideline}.\\

%\begin{comment} %%%%%%%%%%%%%%%%%%%%%%%%% auskommentiert
{\bf \noindent Programmiersprachen C++ und Java}\\
\begin{tabularx}{\linewidth}{lX}
\hline
\bf Thema & \bf Erklärung\\
\hline
Anweisungen & Pro Zeile darf höchstens eine Anweisung notiert werden. Lange Anweisungen dürfen selbstverständlich mehrere Zeilen umfassen und sollen sinnvoll und lesbar formatiert werden.\\
\hline
Zeilenkommentare & Zeilenkommentare sind stets {\bf über} der Zeile anzulegen, auf welche sie sich beziehen. Offensichtliche Informationen, die der Code auch so preisgibt sollen nicht extra wiederholt werden; Also nicht:\\
& \lstinputlisting{Code/Falsche_Kommentare.cpp}\\
\hline
Tabulator & Untergeordnete Anweisungen, beispielsweise unter Schleifen, If-Anweisungen, Switches, Matches oder in Scopes sind pro Ebene um 4 Whitespaces einzurücken. \\
\hline
Entwicklerdokumentation & Für die automatische Generierung der Entwicklerdoku- \\
\& Kommentare & mentation soll Doxygen verwendet werden. Die Struktur der Kommentare muss daher der von Doxygen unterstützten Syntax folgen. \\
& Insbesondere ist jede Funktion hinsichtlich ihrer Funktion, den Parametern und den Rückgabewerten bei ihrer Implementierung zu dokumentieren, wie im folgenden Beispiel: \\
& \lstinputlisting{Code/Doxygen_Funktion.cpp}\\
\hline  
\end{tabularx}
\clearpage
{\noindent \bf Ausschließlich C++}\\
\begin{tabularx}{\linewidth}{lX}
\hline
\bf Thema & \bf Erklärung\\
\hline
const & Das Schlüsselwort const soll nach Möglichkeit immer wenn möglich verwendet werden. Konstante Variablen, \gls{Data Member}s, Funktionen und Argumente ermöglichen eine Form von compile-time Typüberprüfung.\\
& Wir erachten daher folgende Fälle für die Verwendung von const als Sinnvoll:\\
& Wenn eine Funktion garantiert, dass es eine per Referenz oder als Pointer übergebene Variable nicht verändert, sollten diese entsprechend markiert werden: const \&var bzw. const *var\\
& Funktionen (einer Klasse) sollten wenn möglich ebenfalls als const gekennzeichnet werden. Beispielsweise sollten getter-Funktionen (fast) immer konstant sein, da sie keine Member der Klasse verändern (sollten).\\
& Andere Funktionen sollten const sein, wenn: Sie keine non-const Funktionen aufrufen, keine \gls{Data Member}s verändern und keine nicht konstante-Referenz bzw. keinen nicht nicht-konstanten Pointer zu einem solchen zurückgeben. \\
\hline
RAII & 'Resource Acquisition is Initialization' (Ressourcenbelegung ist Initialisierung): Nach Möglichkeit soll dynamischer reservierter Speicher (new, malloc) z.B. zur Verwendung abgeleiteter Klassen durch Polymorphismus etc. automatisch reserviert (Constructur) und freigegeben werden (Destructor).\\   
\hline
Klassen und Strukturen & Passive Objekte, die Daten gruppieren, sollen als structs, alles andere, insbesondere Objekte die aktive Aufgaben bearbeiten als Klassen implementiert werden. \\
\hline
\end{tabularx}

%\end{comment}   %%%%%%%%%%%%%%%%%%%%%%% nicht mehr auskommentiert

%\clearpage


\section{Aufwandsabschätzung}
\subsection{Aufwandsabschätzung für den Datensatz}
\label{info:GTSRB}
Um die \glslink{Neuronales Netzwerk}{Neuronalen Netzwerke} zu trainieren werden Datensätze benötigt. Hierfür wurde der \glqq{}German Traffic Sign Recognition Benchmark\grqq{}-Datensatz der Ruhr-Universität Bochum\footlink{http://benchmark.ini.rub.de/?section=gtsrb\&subsection=news}{02.05.2018} mit ca. 900 Bilder von bis zu 5 Verkehrszeichen aus 43 Klassen, für die \gls{Detektion} ausgewählt.
Außerdem wird der \glqq{}German Traffic Sign Detection Benchmark\grqq{}-Datensatz der Ruhr-Universität Bochum\footlink{http://benchmark.ini.rub.de/?section=gtsdb\&subsection=news}{02.05.2018} verwendet. Er umfasst ca. 50.000 Bilder aufgeteilt auf etwa 400 bis 2000 \glslink{Sample}{Samples} pro Klasse und dient für das Training des Klassifikationsnetzwerkes.\\

Diese Datensätze sind allerdings nicht für das Training ausreichend. Abgesehen davon ist es zielführend, Datensätze direkt auf entsprechenden Endgeräten zu erstellen (also mit der Kamera des \glslink{Smartphone}{Smartphones}) um die Ähnlichkeit zum späteren Eingaberaum zu wahren. Es werden nicht alle zu erkennenden Verkehrszeichen abgedeckt und die Menge an \glslink{Sample}{Samples} pro Verkehrszeichen ist teilweise zu klein, sodass weitere Bilder aufgenommen und \glslink{Label}{gelabelt} werden müssen. Die Netzwerke können erst nach Abschluss dieser Aufgabe auf vollständigen Datensätzen trainiert werden, was voraussichtlich zu schnelleren Erfolgen führt, als ein Training auf Teildatensätzen. Zudem gewährt es mehr Zeit um unterstützende Methoden wie \gls{Tracking} zu implementieren, während die Netze trainiert werden.\\

Die im Folgenden verwendete Einheit \si{\PS} bezeichnet eine Personenstunde. Also genau die mittlere Arbeit, die eine Person pro Stunde leisten kann. Sofern alle benötigten Ressourcen in ausreichender Menge zu Verfügung stehen und parallel nutzbar sind, können n Personen parallel n Personenstunden in einer Zeitstunde leisten.\\

\subsubsection{Aufnahmefahrten}
Da ein sehr hoher Aufwand vom Erstellen der Datensätze ausgeht, ist eine obere Grenze für das Aufnehmen vorgesehen. Zum Bestimmen dieser Grenze, wird die zu erwartende Fahrtdauer mithilfe von Erfahrungswerten aus Testfahrten und der folgenden modellhaften Gleichung bestimmt:
\begin{longtabu}{l X[j]}
$Q$ & Anteil der verwertbaren Frames\\
$r$ & Aufnahmeframerate\\
$S$ & Anzahl der \glslink{Sample}{Samples}\\
$t$ & geschätzte Fahrtzeit\\
\end{longtabu}
$$ t \left[\si{\PS}\right] = \frac{\SI{1}{\PS}}{\SI{3600}{\second}} \cdot \dfrac{S \left[1\right]}{Q\left[1\right] \cdot r \left[\si{\hertz}\right]} $$\\

Im \cref{subsec:fahrtdauer} befinden sich unsere Schätzungen für die obigen Parameter, mit diesen ergeben sich: $t_\text{innerorts} = \SI{2.06}{\hour} \approx \SI{2}{\hour}$ und $t_\text{Autobahn} = \SI{2.22}{\hour} \approx \SI{2}{\hour}$\\

Demnach sollen insgesamt vier Stunden Autofahrt bei einer Aufnahmerate von drei Bildern pro Sekunde erstellt werden.
Davon jeweils zwei Stunden innerorts und zwei Stunden auf Autobahnen aufgenommen werden.\\
Mit der hier erwähnten Aufnahme wird sich eine Erweiterung der verwendeten Datensätze um jeweils 1250 \glslink{Sample}{Samples} von Zusatzverkehrszeichen und weiteren 1250 \glslink{Sample}{Samples} von geschwindigkeitsbegrenzenden Verkehrszeichen erhofft.\\

\subsubsection{Aussortieren von Bildaufnahmen ohne Verkehrszeichen}
Um die Aufnahmen für die \gls{Detektion} und \gls{Klassifikation}  aufzubereiten müssen diese gelabelt werden. In einer ersten Iteration werden zunächst Aufnahmen aussortiert, die keine verwertbaren Verkehrszeichen enthalten:

\begin{longtabu}{l X[j]}
$a$ & Aussortierrate\\
$d$ & aufgezeichnete Videomateriallänge\\
$r$ & Aufnahmeframerate\\
$t$ & geschätzte Arbeitszeit\\
\end{longtabu}

$$ t \left[\si{\PS}\right] = \frac{d \left[\si{\PS}\right] \cdot r \left[\si{\hertz}\right]}{a \left[\si{\hertz}\right]} $$\\

Anhand der Werte unter \cref{subsec:aussortieren} wird der Aussortieraufwand für geschlossene Ortschaften auf rund $\SI{6}{\hour}$ und für Autobahnen auf rund $\SI{10}{\PS}$ geschätzt, also insgesamt $\SI{16}{\PS}.$\\

\subsubsection{Labeln von Bildaufnahmen mit relevanten Verkehrszeichen}
In der zweiten Iteration werden die \glslink{Sample}{Samples}, welche Verkehrszeichen enthalten mit Metainformationen bezüglich Art, Position und Größe dieser versehen:

\begin{longtabu}{l X[j]}
$l$ & Labelrate\\
$S$ & Anzahl der \glslink{Sample}{Samples}\\
$t$ & geschätzte Arbeitszeit\\
\end{longtabu}

$$ t \left[\si{\PS}\right] = \frac{S \left[1\right]}{l \left[\si{\per\PS}\right]} $$\\

Mit dem Parametern aus \cref{subsec:labeln} ergeben sich Labelingzeiten von rund $\SI{16}{\hour}$ für Aufnahmen innerorts und rund $\SI{4}{\hour}$ für Autobahnaufnahmen.\\\newline

Damit beläuft sich der Zeitaufwand auf:\\
\begin{longtabu}{l r l}
& \SI{4}{\PS} & Aufnahmefahrten\\
+ & \SI{16}{\PS} & Aussortieren von Aufnahmen\\
+ & \SI{20}{\PS} & Labeln von \glslink{Sample}{Samples}\\
\hline
= & \SI{40}{\PS} & Datensatzerweiterung \\
\hline
\hline
\end{longtabu}

Sollte das Detektionsnetzwerk zuverlässig funktionieren, kann es selbstständig aus Online-Ressourcen wie der KITTI-Datensatz des Karlsruher Institut für Technologie\footlink{http://www.cvlibs.net/datasets/kitti/
}{27.04.2018}, Time-Lapse-Videos von Fahrten oder weitere Bildresourcen \glslink{Sample}{Samples} für das Klassifikationnetzwerk entnehmen. Die \glslink{Sample}{Verkehrszeichensamples} aus diesen Quellen müssen eventuell gelabelt werden.\\

\subsection{Rückblickende Beurteilung der Aufwandsabschätzung für den Datensatz}
Wie sich im Nachhinein zeigte, waren die Schätzungen für den Aufwand zur Erstellung des Datensatzes deutlich zu optimistisch gewählt. Vor allem die Labelrate ($l$) wich schwerwiegend ab. Sie war auf Basis der Leistung von einer überdurchschnittlich schnellen Person aus der Gruppe geschätzt worden. Dies stellte nicht die mittlere Labelrate innerhalb der Gruppe dar. Ferner hat die Schätzung wichtige Effekte außer Acht gelassen: beispielsweise wird ein bedeutender Teil der Samples unbrauchbar, nachdem diese auf die relativ geringen Auflösungen, welche die \glslink{Neuronales Netzwerk}{Neuronalen Netzwerke} benötigen, skaliert wurden. Zudem ist das Erstellen und Optimieren der Python-Skripte - welche den Datensatz aus den Einzelbildern extrahieren, in andere Formate umrechnen, Skalierungen durchführen, Label-Klassen von natürlicher Sprache in fortlaufende Nummerierungen übersetzen sowie alle verwendeten Datensätze in einen Gesamtdatensatz zusammenführen - bei der Aufwandsabschätzung überhaupt nicht beachtet worden.\\

Auf den durchgeführten Testfahrten wurde etwa \SI{6.5}{\hour} Videomaterial erzeugt. Bei der konstanten Framerate von \SI{3}{\hertz} beläuft sich damit die Zahl an Rohbildaufnahmen auf etwa \SI{70000}{}. Damit konnten deutlich mehr Bilder aufgenommen werden, als in der ursprünglichen Schätzung gefordert. Allerdings wurden von diesen insgesamt \SI{55000}{} Aufnahmen verworfen, da sie kein Verkehrszeichen beinhalteten. Damit beläuft sich der (experimentell bestimmte) Faktor $Q$ auf $\frac{\SI{70000}{} - \SI{55000}{}}{\SI{70000}{}} = \SI{0.214}{}$ und liegt damit deutlich höher als die Schätzung. Dabei ist zu beachten, dass dieser alle Verkehrszeichen beachtet, demnach auch solche ohne Einfluss auf die derzeitige erlaubte Höchstgeschwindigkeit wie Vorwegweiser oder Vorfahrtsschilder. Zudem beschreibt er den Anteil individuelle Frames in einer Aufnahme, nicht die Häufigkeit der physischen Schilder auf einer gegebenen Strecke. Es war ursprünglich gewünscht, dass möglichst viele individuelle Schilder aufgenommen werden, nicht dieselben aus unterschiedlichen Blickwinkeln. Aufgrund der zeitlichen und wirtschaftlichen Einschränkungen (kein Budget zum Decken der Benzinkosten), ließ sich dies nur bedingt realisieren.\\

Das Aussortieren der Verkehrszeichen wurde bemerkenswert gut abgeschätzt und hat genau die berechneten \SI{16}{\PS} benötigt.\\

Die Dauer des Labelns der Verkehrszeichen wurde deutlich unterschätzt. Der Aufwand belief sich auf insgesamt rund \SI{184}{\PS}, also \SI{23}{\hour} pro Person - also das Neunfache (!) der ursprünglichen Schätzung. Darauf basierend ergibt sich eine mittlere Labelrate $l$ von \SI{81.52}{\per\hour}.\\

Der Aufwand der Python-Skripte wird im Nachhinein mit etwa \SI{100}{\PS} bemessen.\\

\subsection{Projektplan}
\label{subsec:projektplan}

\includesvg[width=1\linewidth]{Grafiken/Project_Plan.svg}\\

\subsection{Meilensteine}
\label{subsec:meilensteine}
\subsubsection{[1] \gls{App} Prototyp, bis 02.05. (50h)}
Der erste Prototyp soll eine testweise Realisierung der Benutzeroberfläche beinhalten. Weiterhin soll \gls{TensorFlow Lite} über eine native Library eingebunden werden, welche den Ausgangspunkt für die \gls{Filterverwaltungs-Bibliothek}  bilden soll.\\
\\
\textbf{Testkriterium}: Der Prototyp lässt sich auf einem Android-Smartphone starten. Die bis hierhin implementierten Realisierungen der Benutzeroberfläche, sollten vom Prinzip der Spezifikation im Pflichtenheft übereinstimmen. Desweiteren muss eine Einbindung von TesorFlow Lite funktionieren, was durch ein Laden der Bibliothek getestet wird.\\

\subsubsection{[2] Aufnahme und Labeln aller \glslink{Sample}{Samples}, bis 10.05. (50h)}
Die Autofahrten zur Aufnahme der \glslink{Sample}{Samples} werden abgeschlossen. Anschließend werden alle Bilder, auf denen relevante Verkehrszeichen zu sehen sind, extrahiert und entsprechend gelabelt.\\
\\
\textbf{Testkriterium}: Es wird eine gegenseitige stichprobenartige Kontrolle durchgeführt. Dadurch fallen Uneinigkeiten über die Qualität des Labelings auf. Der Meilenstein ist erst dann abgeschlossen, wenn die Samples in einem zur Training verwendbaren Qualität und Quantität vorhanden sind.\\ 

\subsubsection{[3] App, bis 31.05. (300h)}
Alle Funktionen der \gls{App} unabhängig von der \gls{Verkehrszeichen-API} sind zu implementieren, die Anbindung an diese ist vorzubereiten: Hierzu zählen die Realisierung der Aufnahme von Bildern über die Kamera sowie die Realisierung der Benutzeroberfläche.\\
\\
\textbf{Testkriterium}: Die Benutzeroberfläche der App ist eine ggf. leicht veränderte Version der Oberfläche aus Meilenstein 1. Das \gls{UI} soll in deutscher und englischer Sprache verfügbar sein, wobei Englisch die Fallback-Sprache darstellt. Letzteres ist mit einem \gls{Smartphone}, bei welchem nicht Deutsch als Gerätesprache eingestellt ist, zu testen. Beim Start der \gls{App} kann auch der geforderte Disclaimer überpüft werden.\\
Die Geschwindigkeitsmessung wird in einer Testfahrt mit dem Fahrzeugtachometer verglichen. Grundsätzliche sollten diese übereinstimmen, jedoch ist bei konstanter Geschwindigkeit des Fahrzeuges eine Abweichung um $\pm 5\%$ vom Tachometer akzeptabel.\\
Zum Überprüfen der Kamerafunktionalität muss in einem Debug-Menü das Bild ohne signifikanten Zeitunterschied\footnote{d.h.: der Zeitunterschied würde die Funktion des Gesamtsystems nicht beeinträchtigen} erkennbar sein.\\
Im Kalibrierungsmenü muss die Rotation des \gls{Smartphone}s zumindest als Textausgabe angezeigt werden. Bestätigt wird dies durch Drehen um $\pm90^\circ$ um die \glslink{Drehachsen}{Roll- und Nickachse} von der Nulllage (Gerät hängt waagerecht) aus.\\
Die Anforderungen, dass die Geschwindigkeitsermittelung abschaltbar sein soll und dass die Länge der Historie einstellbar ist, wird überprüft, indem diese Einstellungen im entsprechenden Menü vorgenommen werden. \\

\subsubsection{[4] Filterverwaltungs-Bibliothek, bis 31.05. (120h)}
Alle Funktionen der Bibliothek (statisch oder dynamisch) für die Filterverwaltung sind zu implementieren. Darunter u.a. die Realisierung der \glslink{Pipes and Filters}{Pipes-and-Filters}-Architektur, die Verwendung von \gls{TensorFlow Lite} zur Realisierung von \glslink{Neuronaler Filter}{Neuronalen Filtern} sowie die jeweiligen Basisklassen für weitere \glslink{Filter}{Filtertypen}.\\
\\
\textbf{Testkriterium}: Es lässt sich ein Filter anlegen, welcher ein beliebiges, in TensorFlow trainiertes \gls{Neuronales Netzwerk}, lädt. Zusätzlich soll man einen Input geben können und die zum Output verstrichene Zeit messen können.\\
\\
\subsubsection{[5] Verkehrszeichen-API und Neuronale Netzwerke, bis 07.06. (450h)}
Die Einbindung der  \gls{Filterverwaltungs-Bibliothek}  ist die Voraussetzung für die \gls{Verkehrszeichen-API}: Diese wird genutzt um die entsprechenden \gls{Filter} zu realisieren. Die \glslink{Neuronales Netzwerk}{Neuronalen Netzwerke} für den \glslink{Filter}{Detektions- und Klassifizierungsfilter} sind zu entwerfen und zu trainieren und sollen anschließend in die \gls{API} eingebunden werden.\\
\\
\textbf{Testkriterium}: Die \gls{Verkehrszeichen-API} kann sowohl das Detektion- als auch den Klassifikationsfilter anlegen. Dort sollte ein Testbild aus dem Datensatz geladen und ausgewertet werden können. Dieses Testbild darf nicht zum Training der Neuronalen Netzwerke verwendet werden. Wenn auf dem Testbild die geschwindigkeitsregulierenden Verkehrszeichen detektiert und klassifiziert wurden, gilt der Meilenstein als abgeschlossen.\\
\\
\subsubsection{[6] \gls{App} Verkehrszeichen-API-Anbindung, bis 14.06. (40h)}
Die \gls{Verkehrszeichen-API} ist als native Bibliothek in die \gls{App} einzubinden und alle Einzelkomponenten sind mittels (Java Native) Interface Funktionen zu verbinden.\\
\\
\textbf{Testkriterium}: Die \gls{App} ist in der Lage, das Kamerabild an die Filterverwaltungs-Bibliothek weiterzugeben.
Diese muss dann mithilfe der Verkerszeichen-API eine Auswertung des Bildes machen.\\
Die Anbindung gilt als abgeschlossen, sobald die eigens trainierten \glslink{Neuronales Netzwerk}{Neuronalen Netze} mittels der Verkehrszeichen-API in der \gls{App} verwendet werden können.
Dies wird getestet, indem ein \gls{Smartphone} mit dem Sichtfeld auf ein Verkehrszeichen ausgerichtet wird. Dabei ist eine Ausgabe von der \gls{Filterverwaltungs-Bibliothek} zu erwarten.\\

\subsubsection{[7] Systemtest und Dokumentation, bis 04.07. (480h)}
Anhand der im Pflichtenheft spezifizierten Testfälle und Abnahmekriterien ist das \gls{System} auf seine Funktionalität und die Erfüllung der Anforderungen hin zu überprüfen. Die erforderlichen Korrekturen und Bugfixes sind durchzuführen.\\
\\
\textbf{Testkriterium}: Die im Pflichtenheft spezifizierten Testfälle müssen erfüllt sein.\\

%\begin{comment}
\begin{longtabu}{|l|X[j]|X[j]|l|}
\hline 
ID & Meilenstein & Beschreibung & Aufwand  \\
\hline
1 & \gls{App} Prototyp & Der erste Prototyp soll eine testweise Realisierung der Benutzeroberfläche beinhalten. Weiterhin soll \gls{TensorFlow Lite} über eine native Library eingebunden werden, welche den Ausgangspunkt für die  \gls{Filterverwaltungs-Bibliothek}  bilden soll. & bis 02.05. (50h) \\
\hline
2 & Aufnahme und Labeln aller \glslink{Sample}{Samples} & Die Autofahrten zur Aufnahme der \glslink{Sample}{Samples} werden abgeschlossen. Anschließend werden alle Bilder auf denen relevante Verkehrszeichen zu sehen sind extrahiert und entsprechend zu labeln.
& bis 10.05 (50h)\\
\hline
3 & \gls{App} & Alle Funktionen der \gls{App} unabhängig von der \gls{Verkehrszeichen-API} sind zu implementieren, die Anbindung an diese ist vorzubereiten: Hierzu zählen die Realisierung der Aufnahme von Bildern über die Kameraoberfläche sowie die Realisierung der Benutzeroberfläche. Für die Verwendung der \gls{Verkehrszeichen-API} sind die entsprechenden (Java Native) Interface Funktionen zu implementieren & 31.05. (300h)\\
\hline
4 & Filterverwaltungs-Bibliothek & Alle Funktionen der Bibliothek (statisch oder dynamisch) für die \glslink{Filterverwaltungs-Bibliothek}{Filterverwaltung} sind zu implementieren. Darunter u.a. die Realisierung der \glslink{Pipes and Filters}{Pipes-and-Filters}-Architektur, die Verwendung von \gls{TensorFlow Lite} zur Realisierung von \glslink{Neuronaler Filter}{Neuronalen Filtern} sowie die jeweiligen Basisklassen für weitere \glslink{Filter}{Filtertypen}. & 31.05. (120h)\\
\hline
5 & \gls{Verkehrszeichen-API} & Die Einbindung der  \gls{Filterverwaltungs-Bibliothek}  ist die Voraussetzung für die \gls{Verkehrszeichen-API}: Diese wird genutzt um die entsprechenden \gls{Filter} zu realisieren. Die \glslink{Neuronales Netzwerk}{Neuronalen Netzwerke} für den Detektions- und Klassifizierungsfilter sind zu entwerfen und zu trainieren und sollen anschließend in die \gls{API} eingebunden werden. & 07.06. (450h)\\
\hline
6 & \gls{App} \gls{Verkehrszeichen-API}-Anbindung & Die \gls{Verkehrszeichen-API} ist als native Library in die \gls{App} einzubinden, sodass alle Einzelkomponenten zusammengefügt werden & 14.06. (40h) \\
\hline
7 & Systemtest & Anhand der im Pflichtenheft spezifizierten Testfälle und Abnahmekriterien ist das \gls{System} auf seine Funktionalität und die Erfüllung der Anforderungen hin zu überprüfen. Die erforderlichen Korrekturen und Bugfixes sind durchzuführen & 04.07. (480h) \\
\hline
\end{longtabu}
%\end{comment}

\subsection{Zu realisierende Anforderungen in der ersten Iteration}
Hauptaufgabe in der ersten Iteration ist vor Allem die Erstellung des Pflichtenheftes und des Reviewdokumentes.\\
Das Modell des agilen Vorgehens sieht es außerdem vor, einen ersten Prototypen zu entwerfen. Hierbei streben wir an, die als kritisch erachtete Anbindung der C++ \gls{API} von \gls{TensorFlow Lite} an die Android \gls{App} zu realisieren: Hierfür muss \gls{TensorFlow Lite} als eine statische oder dynamische Bibliothek kompiliert werden, damit diese sich dann in eine native library (sh. Android NDK) einbinden lässt. Weiterhin soll eine erste testweise Umsetzung der grafischen Benutzeroberfläche erfolgen, um unsere Design Entwürfe auf die grundlegende Umsetzbarkeit hin zu untersuchen.

\chapter{Konkurrenz}

Nachfolgend soll ein Überblick über bereits verfügbare Applikationen unter Android oder iOS zur Erkennung von Verkehrszeichen gegeben werden.\\

Android: \textbf{\glqq{}Traffic Sign Detector\grqq{}} von \glqq{}Aleksander Jesmanczyk\grqq{}\footlink{https://play.google.com/store/apps/details?id=pl.jesmanczyk.android.driverassistant}{01.05.2018}
\hline\vspace{4pt}
Die \gls{App} ist für die Erkennung von (wahrscheinlich) polnischen Verkehrszeichen ausgelegt. Zur Erkennung wird TensorFlow mit MobileNetV1 und Single Shot Detector verwendet. Die Benutzeroberfläche entspricht nicht den empfohlenen Google Material-Design Guidelines\footnote{\label{foot:guideline}\link{https://developer.android.com/design/material/index.html}, 01.05.2018}. Außerdem erwies sich die Erkennung bei einem kurzen Test mit etwa 3 bis 4 Sekunden Reaktionszeit als langsam.\\
Getestet wurde die Version 1.9 am 30.04.2018.\\

Android: \textbf{\glqq{}Road Sign Recognition\grqq{}} von \glqq{}IRAI\grqq{}\footlink{https://play.google.com/store/apps/details?id=road.signs.recognition}{01.05.2018}
\hline\vspace{4pt}
Die \gls{App} ist nur für die Erkennung von geschwindigkeitsbegrenzenden Verkehrszeichen mit roten Rändern ausgelegt. Auch entspricht die Benutzeroberfläche wiederum nicht den empfohlenen Google Material-Design Guidelines.\footref{foot:guideline}\\
Aktuell (Stand: 10.06.2018) ist diese \gls{App} nicht mehr im Google Play Store verfügbar.\\

iOS: \textbf{\glqq{}Traffic speed camera detector\grqq{}} von \glqq{}Christian Neubauer\grqq{}\footlink{https://itunes.apple.com/gb/app/traffic-speed-camera-detector/id1237199452?mt=8}{01.05.2018}
\hline\vspace{4pt}
Die \gls{App} ist für die Erkennung deutscher Verkehrszeichen ausgelegt. Die Erkennung erwies sich bei einem kurzen Test mit 3 bis 4 Sekunden Reaktionszeit als langsam und eindeutig identifizierbare Geschwindigkeitsbegrenzungen wurden in den meisten Fällen nicht korrekt erkannt. In der kostenfreien Version konnten nur geschwindigkeitsbegrenzende Verkehrszeichen bis 50 km/h erkannt werden. Um die vollständige Funktionalität zu bekommen, müsste man für 3,99€ die Pro-Version kaufen.\\
Getestet wurde die Version 1.2.5. am 30.04.2018.\\

Die Recherche hat  ergeben, dass diese Art von Applikation für Mobilgeräte prinzipiell bereits existiert. Allerdings haben sich die getesteten Apps in der Erkennung von geschwindigkeitsbegrenzenden Verkehrszeichen unter Tageslicht und klarer Sicht als nicht verlässlich genug, langsam oder zu eingeschränkt erwiesen. Die im Rahmen dieses Softwareprojekts zu entwickelnde Applikation soll mit Fokus auf deutschen, geschwindigkeitsbezogenen Zeichen zuverlässig selbige unter den beschriebenen Betriebsbedingungen erkennen. Außerdem soll sie ebenfalls die Erkennung von Zusatzschildern ermöglichen, ein Feature, welches wir bei keiner getesteten \gls{App} gefunden haben. Zu guter Letzt soll die grafische Darstellung der Benutzeroberfläche weitgehend an den Google Material-Design Guidelines\footref{foot:guideline} orientiert sein. Ein abschließender Vergleich mit den aufgelisteten Konkurrenzapps ist aufgrund ihrer beschriebenen Einschränkungen nur bedingt sinnvoll. Ausschließlich die genannte iOS \gls{App} lässt sich - unter identischen Bedingungen - in einem fairen Test vergleichen.

\chapter{Ergebnisse der ersten Iteration}
In der ersten Iteration wurden im wesentlichen die Dokumente Pflichtenheft und Reviewdokument einschließlich Projektplanung und Entwurf angefertigt.\\
Darüber hinaus wurden viele Voraussetzungen für das weitere Vorgehen in der Implementierungsphase geschaffen: Es wurden erste Tests mit möglicherweise zu verwendenden \glslink{Neuronales Netzwerk}{neuronalen Netzwerkmodellen} durchgeführt, um so bereits potentielle Kandidaten für die letztendliche Realisierung zu ermitteln.\\
Für die Android \gls{App} wurde \gls{TensorFlow Lite} als dynamische Bibliothek kompiliert, damit dessen C++ \gls{API} verwendet werden kann. Damit einher ging die Realisierung des Prototypens: Für diesen wurden neben einer ersten Implementierung der Grundzüge der grafischen Benutzeroberfläche auch bereits erfolgreich die TensorFlow Abhängigkeiten eingebunden und eine erste Kommunikation zwischen der Android \gls{App} mit der nativen Bibliothek, welche die Grundlage für die spätere  \gls{Filterverwaltungs-Bibliothek}  bildet und folglich \gls{TensorFlow Lite} zur Realisierung \gls{Neuronaler Filter} verwendet, realisiert. Die Implementierung erster Grundzüge der grafischen Oberfläche hat gezeigt, dass unser geplantes Hauptdesign (sh. Plichtenheft) umsetzbar ist.\\

\section{Festlegung der Aufgaben für die zweite Iteration}
Die Aufgaben für die nächste Iteration sind v.a. die Implementierung der Softwareaspekte. Das genaue Vorgehen ist in  \cref{subsec:projektplan} festgelegt und umfasst die Punkte 2 - 6. 

\end{comment} %%% THE COMMENT ENDS!
\end{document}